# NetDissectResults
Comparing the interpretability of different DL models. Based on the NetDissect-lite repo


## Background
Interpretability is important because

This work is based on previous [work](http://netdissect.csail.mit.edu/) by David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, and Antonio Torralba, who introduced Network Dissection - more specifically the paper [Network Dissection: Quantifying Interpretability of Deep Visual Representations](http://netdissect.csail.mit.edu/final-network-dissection.pdf) and the belonging repository [NetDissect-Lite](https://github.com/CSAILVision/NetDissect-Lite).

Our work is part of the course Research Methodology and Scientific Writing at KTH.  

## Research Question


## Approach
